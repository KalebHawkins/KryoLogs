<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>openshift on KryoLogs</title><link>https://KalebHawkins.github.io/KryoLogs/tags/openshift/</link><description>Recent content in openshift on KryoLogs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 22 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://KalebHawkins.github.io/KryoLogs/tags/openshift/index.xml" rel="self" type="application/rss+xml"/><item><title>Openshift - Authentication Cluster Operator Degraded (OAuthServerRouteEndpointAccessibleControllerAvailable)</title><link>https://KalebHawkins.github.io/KryoLogs/posts/openshift/authentication-operator-degraded/</link><pubDate>Sat, 22 Apr 2023 00:00:00 +0000</pubDate><guid>https://KalebHawkins.github.io/KryoLogs/posts/openshift/authentication-operator-degraded/</guid><description>Issue Summary When performing an oc get co the authentication cluster operator is reporting a degraded state with the following message.
OAuthServerRouteEndpointAccessibleControllerAvailable: Get &amp;#34;https://oauth-openshift.apps.zone.domain.com/healthz&amp;#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) Root Cause This can be a result of many different things, network issues, domain name resolution issues, etc. In my case the authentication pods and authentication-operator pod running in the cluster were failing to reconciliate due to some node modifications.</description></item><item><title>Openshift - Working with vSphere Storage Classes</title><link>https://KalebHawkins.github.io/KryoLogs/posts/openshift/vsphere-storageclasses/</link><pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate><guid>https://KalebHawkins.github.io/KryoLogs/posts/openshift/vsphere-storageclasses/</guid><description>In this post we are going to look at two different things. First, we will look at modifing the default datastore for our vsphere storage class. Second, we will look at creating storage classes that specify the datastore.
The Default Datastore This change will trigger the nodes to reboot. Always make sure you are in an open maintenaince window or that your applications are designed to work through pods migrating from node to node for less impact.</description></item><item><title>Openshift - Managing/Modifing Machinesets</title><link>https://KalebHawkins.github.io/KryoLogs/posts/openshift/machinesets/</link><pubDate>Wed, 12 Apr 2023 00:00:00 +0000</pubDate><guid>https://KalebHawkins.github.io/KryoLogs/posts/openshift/machinesets/</guid><description>In this document we are going to review the process of modifing a machineset to increase resources, for this example we will be increasing memory.
Modify The Machineset In the first step we modify the machine set we want to modify. First we decide which machineset we want to modify we can get the machinesets using the following.
oc get machineset -n openshift-machine-api Now we want to modify our machineset&amp;rsquo;s memory.</description></item><item><title>Openshift - Clsuter Ownership Transfer</title><link>https://KalebHawkins.github.io/KryoLogs/posts/openshift/ownership-transfer/</link><pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate><guid>https://KalebHawkins.github.io/KryoLogs/posts/openshift/ownership-transfer/</guid><description>Overview Transfering Ownership Update the Pull Secret Verification Steps Reference Overview There are two steps to transfer ownership to a new user or organization.
Initiate the transfer in Openshift Cluster Manager. Change the cluster pull secret to the new owner&amp;rsquo;s pull secret from CLI, The second step must take place within 5 days of the transfer initiation of cluster transfer from the Openshift Cluster Manager.
Transfering Ownership Login to the Openshift Cluster Manager as the current owner.</description></item></channel></rss>