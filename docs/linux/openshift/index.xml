<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Openshift on KryoLogs</title><link>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/</link><description>Recent content in Openshift on KryoLogs</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 30 May 2024 14:50:23 -0500</lastBuildDate><atom:link href="https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/index.xml" rel="self" type="application/rss+xml"/><item><title>VSphere StorageClasses</title><link>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/vsphere-storageclasses/</link><pubDate>Thu, 30 May 2024 14:50:23 -0500</pubDate><guid>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/vsphere-storageclasses/</guid><description>In this post we are going to look at two different things. First, we will look at modifying the default datastore for our vsphere storage class. Second, we will look at creating storage classes that specify the datastore.
The Default Datastore link This change will trigger the nodes to reboot. Always make sure you are in an open maintenance window or that your applications are designed to work through pods migrating from node to node for less impact.</description></item><item><title>Ownership Transfer</title><link>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/ownership-transfer/</link><pubDate>Thu, 30 May 2024 14:50:10 -0500</pubDate><guid>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/ownership-transfer/</guid><description>Overview linkThere are two steps to transfer ownership to a new user or organization.
Initiate the transfer in Openshift Cluster Manager. Change the cluster pull secret to the new owner&amp;rsquo;s pull secret from CLI, The second step must take place within 5 days of the transfer initiation of cluster transfer from the Openshift Cluster Manager.
Transferring Ownership link Login to the Openshift Cluster Manager as the current owner. Select the cluster you want to transfer from the Clusters list.</description></item><item><title>Machinesets</title><link>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/machinesets/</link><pubDate>Thu, 30 May 2024 14:49:58 -0500</pubDate><guid>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/machinesets/</guid><description>In this document we are going to review the process of modifying a machineset to increase resources, for this example we will be increasing memory.
Modify The Machineset linkIn the first step we modify the machine set we want to modify. First we decide which machineset we want to modify we can get the machinesets using the following.
oc get machineset -n openshift-machine-api Now we want to modify our machineset&amp;rsquo;s memory.</description></item><item><title>Authentication Operator Degraded</title><link>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/authentication-operator-degraded/</link><pubDate>Thu, 30 May 2024 14:49:49 -0500</pubDate><guid>https://kalebhawkins.github.io/KryoLogs/docs/linux/openshift/authentication-operator-degraded/</guid><description>Issue Summary linkWhen performing an oc get co the authentication cluster operator is reporting a degraded state with the following message.
OAuthServerRouteEndpointAccessibleControllerAvailable: Get &amp;#34;https://oauth-openshift.apps.zone.domain.com/healthz&amp;#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) Root Cause linkThis can be a result of many different things, network issues, domain name resolution issues, etc. In my case the authentication pods and authentication-operator pod running in the cluster were failing to reconciliate due to some node modifications.</description></item></channel></rss>